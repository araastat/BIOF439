---
title: Visualization in different applications
author: Abhijit Dasgupta, PhD
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=F, warning=F, comment = ' ', cache=TRUE,
                      fig.height=5)
setwd(here::here('slides/lectures'))
library(tidyverse)
theme_439 <- theme_classic()+theme(axis.text = element_text(size=14),
                                axis.title = element_text(size=16),
                                legend.text = element_text(size=14),
                                legend.title = element_text(size=16),
                                plot.title = element_text(size=18),
                                plot.subtitle = element_text(size=16),
                                plot.caption = element_text(size=12))
theme_set(theme_439)

## If you don't have Garrett Aden-Buie's animations, clone the repository https://github.com/gadenbuie/tidyexplain
## or install (devtools::install_github("gadenbuie/tidy-animated-verbs"))

```

layout: true

<div class="my-header">
<span>BIOF 439: Data Visualization using R</span></div>

---

## Goals

1. Visualization in biomedical applications and models
1. Visualizing spatial data using maps
1. Bioinformatics

---
class: middle, inverse

# Biomedical applications

---
class: middle

# Survival analysis

---

## Survival analysis

Survival analysis is the analysis of time-to-event data. In biomedical research, *event* can mean

1. death
1. recurrence or relapse (cancer, infection)
1. equipment failure (pacemakers, orthopedic implants)

--

You need two pieces of information: 
1. the time of the event or the time you last saw the subject, and 
1. the status (dead/alive) the last time you saw the subject. If subject is alive, you call that observation _censored_, since you didn't observe the subject long enough to see the event happen.
---

## Survival analysis

The basic graphical tool in survival analysis is the _Kaplan-Meier curve_, which shows the 
proportion of subjects **still surviving** at any given time, with 100% alive at time 0. 

The Kaplan-Meier curve is computed using the function `survival::survfit` and uses the
same formula interface as usual models, with one little quirk.

```{r biomed-1}
library(survival)
brca <- readxl::read_excel('data/BreastCancer_Clinical.xlsx', .name_repair = 'universal')
fit <- survfit(Surv(OS.Time, OS.event) ~ PR.Status, data = brca)
```

We have a composite dependent variable, comprising both the time and status of each event. It is 
encapsulated in the function `Surv` (note capitalization)

---

## Kaplan-Meier curve

.left-column70[
```{r biomed-2, echo=FALSE, warning=FALSE, fig.height=7.5, fig.width=10.5}
library(survminer)
(plt <- ggsurvplot(fit, pval=TRUE, pval.method = TRUE, risk.table=TRUE,
                   legend.labs = c('PR-','PR+'),
                   xlab = 'Time (days)', 
                   ggtheme=theme_439))
```
]
.right-column70[
+ Small ticks are times when subjects are censored
+ The log-rank test tests if the stratified curves are statistically different
+ The risk table gives the number still alive at different times.
]
---

## Kaplan-Meier curve

The plot is generated by the following code:

```{r biomed-3, eval=FALSE}
library(survminer)
(plt <- ggsurvplot(fit, pval=TRUE, pval.method = TRUE, risk.table=TRUE,
                   legend.labs = c('PR-','PR+'),
                   xlab = 'Time (days)'))
```

+ The actual plot can be accessed using `plt$plot` and is a regular **ggplot2** object
+ The table can be accessed using `plt$table` and is _also_ a **ggplot2** object

There is a lot of customization of these plots that are possible. See 
[https://rpkgs.datanovia.com/survminer/index.html](https://rpkgs.datanovia.com/survminer/index.html) for
tutorials and details.

---
class: middle

# Regression results

---

## Displaying the results of a regression model

We're used to seeing the results of a regression analysis in tables, but graphically displaying them
may make them easier to understand. 

We'll use a toy example using the `mpg` data.

We fit a linear regression model using 

```{r biomed-4}
mpg <- mpg %>% 
  mutate(year = as.factor(year)) %>% 
  mutate(trans = str_extract(trans, '[:alnum:]+')) %>% 
  mutate(cyl = as.factor(cyl))
fit <- lm(cty ~ year + trans + cyl + drv + class, data=mpg)
```

This models city mpg against year, type of transmission, number of cylinders, type of drive, and class of car.

---

## Displaying the results of a regression model

As a table, these results look like 

.left-column70[
```{r biomed-5, cache=FALSE}

knitr::kable(broom::tidy(fit))
```
]
.right-column70[
Obviously this needs cleaning up

We'd fix the terms, and reduce the number of decimal places to 2

The point is, it's relatively hard to understand the relative effects of different levels.
]

---

## Displaying the results of a regression model

As a figure, it's probably a bit better

.left-column70[
```{r biomed-6, fig.height=4}
results = broom::tidy(fit) %>% filter(term !="(Intercept)")
ggplot(results)+
  geom_pointrange(aes(x=term, y=estimate, 
                      ymin = estimate-2*std.error, ymax=estimate+2*std.error))+
  geom_hline(yintercept=0, linetype=2) + 
  coord_flip() + 
  theme_439
```
]
.right-column70[
We plot the estimate and 95% confidence interval for each term

Provide reference line of 0

.heatinline[Can see increasing and decreasing patterns within variable levels]

We'll work on cleaning this picture up in a tutorial
]

---
class: inverse

## A learning note

You've been gaining some experience in creating graphics. 

I'll increasingly be providing complete code, and will expect you to work on parsing 
that code and understanding what the different parts are doing

One of the nice things about learning an open-source language is that there are plenty of
examples out there, and you're allowed (for the most part) to copy others' code. So developing
the skill of understanding other people's code is really useful and somewhat important.

.saltinline[Reach out to me if it really feels mysterious and arcane. I'm not teaching mystical arts here.]

---

## Logistic regression

We'll use the `PimaIndianDiabetes2` data from the **mlbench** package

```{r biomed-7}
library(mlbench); data("PimaIndiansDiabetes2") # 2 commands separated by ;
fit_logistic <- glm(diabetes ~ pregnant + pressure + triceps + mass, 
                    data = PimaIndiansDiabetes2, 
                    family='binomial') # This option makes this logistic regression
```

The unifying step to displaying the results of most regression modeling is `broom::tidy`. We'll transform the 
results a bit, since logistic regression provides log-odds ratios and we will display the odds ratios.

```{r biomed-8, cache=FALSE}
results <- broom::tidy(fit_logistic)
results <- results %>% 
  mutate(OR = exp(estimate),
         LCB = exp(estimate - 2*std.error),
         UCB = exp(estimate + 2*std.error)) %>% 
  filter(term != '(Intercept)')
```

---

## Logistic regression

.left-column70[
```{r biomed-9, cache=FALSE}
ggplot(results)+
  geom_pointrange(aes(x = term, y = OR, ymin = LCB, ymax = UCB))+
  geom_hline(yintercept = 1, linetype=2)+
  coord_flip()
```
]
.right-column70[
The graph makes it clear that number of pregnancies and body mass significantly influence the odds of being diabetic, but blood pressure and tricep size do not
]

---

## Cox proportional hazards regression

For survival data, Cox regression is typically used to model the *hazard rate*, i.e. the instantaneous
risk of having an event. 

We'll use the breast cancer dataset to do this, after some data munging

```{r biomed-10}
library(survival)
brca1 <- brca %>% 
  mutate(ER.Status = ifelse(ER.Status == 'Indeterminate', NA, ER.Status),
         HER2.Final.Status = ifelse(HER2.Final.Status=='Equivocal', NA, HER2.Final.Status))
fit_cox <- coxph(Surv(OS.Time,OS.event) ~ ER.Status + PR.Status + HER2.Final.Status, data=brca1)
(results <- broom::tidy(fit_cox))
```

Notice that a Cox regression does not have an intercept term
---

## Cox regression

.left-column70[
```{r biomed-11, fig.height=3}
results <- results %>% 
  mutate(HR = exp(estimate),
         LCB = exp(estimate - 2*std.error),
         UCB = exp(estimate + 2*std.error))
ggplot(results)+
  geom_pointrange(aes(x = term, y = HR, 
                      ymin = LCB, ymax = UCB)) +
  geom_hline(yintercept = 1, linetype=2)+
  coord_flip()+
  theme_439

```

]
.right-column70[
These results may seem counter-intuitive

One may need to do some model building to see what model fits the data well, i.e.
what variables and transformed variables should be included in the model.
]

---

## Creating a function for these plots

We've basically used the same code to create the graphs in all three cases, albeit with
some modest data transformations. 

A general rule is that if you're using the same code more than twice, you should probably make it into a 
function, so you avoid copy-and-paste of code and the mistakes that engenders

```{r biomed-12}
plt_reg_results <- function(results, reflevel=0){
  require(ggplot2)
  plt <- ggplot(results)+
    geom_pointrange(aes(x = term, y = estimate, 
                        ymin = LCB, ymax = UCB))+
    geom_hline(yintercept = reflevel)+
    coord_flip()
  return(plt)
}
```

You should document what format `results` should be in, and what `reflevel` means using comments

With such a function, you might need to do a bit more data munging, but creating the plots becomes a unified process.

---

## Creating a function for these plots

.pull-left[
```{r biomed-13}
broom::tidy(fit) %>% 
  mutate(LCB = estimate - 2*std.error,
         UCB = estimate + 2*std.error) %>% 
  filter(term!='(Intercept)') %>% 
  plt_reg_results()
```

]
.pull-right[
```{r biomed-14}
broom::tidy(fit_logistic) %>% 
  mutate(LCB = exp(estimate - 2*std.error),
         UCB = exp(estimate + 2*std.error),
         estimate = exp(estimate)) %>% 
  filter(term != '(Intercept)') %>% 
  plt_reg_results(reflevel=1)
```

]
